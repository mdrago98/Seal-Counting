{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Understanding Resnet\n",
    "\n",
    "Training Deep neural networks suffers from a number of problems namely:\n",
    "\n",
    "- The vanishing gradient problem (solved using RelU and Batch Normalisation)\n",
    "- Degradation\n",
    "\n",
    "The authors noted that by adding additional layers the training errors increased and accuracy decreased.\n",
    "The problem couldn't be attributed to overfitting due to high degree of training error.\n",
    "\n",
    "\n",
    "![degradation](degradation.png)\n",
    "\n",
    "Their research shows that deep neural network architectures fail to recognise the Identity function.\n",
    "The ResNet architecture aims to specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64).shuffle(10000)\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.central_crop(x, 0.75), y))\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "train_dataset = train_dataset.repeat()\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(5000).shuffle(10000)\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (tf.image.central_crop(x, 0.75), y))\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the resnet residual block using the functional api.\n",
    "![degradation](identity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def res_net_block(input, filters, conv_size):\n",
    "    x = keras.layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, input])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def non_res_block(input_data, filters, conv_size):\n",
    "  x = layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Conv2D(filters, conv_size, activation='relu', padding='same')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  return x\n",
    "\n",
    "inputs = keras.Input(shape=(24, 24, 3))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "num_res_net_blocks = 10\n",
    "for i in range(num_res_net_blocks):\n",
    "    x = res_net_block(x, 64, 3)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "res_net_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/30\n  1/195 [..............................] - ETA: 0s - loss: 3.0956 - acc: 0.0469"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  keras.callbacks.TensorBoard(log_dir='./logs/fit/{}'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")), write_images=True),\n",
    "]\n",
    "res_net_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "res_net_model.fit(train_dataset, epochs=30, steps_per_epoch=195,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}